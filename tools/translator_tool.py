import streamlit as st
import google.generativeai as genai
import time
from google.api_core import exceptions
import json
from streamlit_mic_recorder import mic_recorder

# ===============================================================
# è£œåŠ©é–¢æ•° (ã€åŸç‚¹å›å¸°ã€ã€ã‚·ãƒ³ãƒ—ãƒ« is ãƒ™ã‚¹ãƒˆãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
# ===============================================================
def translate_with_gemini(content_to_process, api_key):
    if not content_to_process or not api_key:
        return None, None

    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')

        # --- ç¬¬ä¸€æ®µéšï¼šã€äºŒæ®µéšèªè¨¼ãƒ—ãƒ­ã‚»ã‚¹ã€(å¤‰æ›´ãªã—ã€æˆ‘ã€…ã®ã€å¡æ™º) ---
        if isinstance(content_to_process, bytes):
            with st.spinner("ï¼ˆã‚ãªãŸã®å£°ã‚’ã€è¨€è‘‰ã«ã€å¤‰ãˆã¦ã„ã¾ã™...ï¼‰"):
                audio_part = {"mime_type": "audio/webm", "data": content_to_process}
                transcription_prompt = "ã“ã®æ—¥æœ¬èªã®éŸ³å£°ã‚’ã€ã§ãã‚‹é™ã‚Šæ­£ç¢ºã«ã€æ–‡å­—ã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ã€‚æ›¸ãèµ·ã“ã—ãŸæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                transcription_response = model.generate_content([transcription_prompt, audio_part])
                processed_text = transcription_response.text.strip()
            if not processed_text:
                st.error("ã‚ãªãŸã®å£°ã‚’ã€è¨€è‘‰ã«ã€å¤‰ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                return None, None
            original_input_display = f"{processed_text} (ğŸ™ï¸éŸ³å£°ã‚ˆã‚Š)"
        else: # strã®å ´åˆ
            processed_text = content_to_process
            original_input_display = processed_text

        # --- ç¬¬äºŒæ®µéšï¼šã‚·ãƒ³ãƒ—ãƒ«ã«ãªã£ãŸã€è„³ã®ä»•äº‹ï¼ˆç¿»è¨³å€™è£œã®ç”Ÿæˆï¼‰ã€ ---
        with st.spinner("AIãŒã€æœ€é©ãªã€3ã¤ã®ã€ç¿»è¨³å€™è£œã‚’ã€è€ƒãˆã¦ã„ã¾ã™..."):
            # â˜…â˜…â˜… ã“ã“ãŒã€æˆ‘ã€…ã®ã€æ–°ãŸãªã‚‹ã€åŸç‚¹ã€ã§ã™ â˜…â˜…â˜…
            system_prompt = """
            # å‘½ä»¤æ›¸: è¨€èªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®ã€æ¢æ±‚è€…ã¨ã—ã¦ã®ã€ã‚ãªãŸã®ã€è²¬å‹™
            ã‚ãªãŸã¯ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã€ç¿»è¨³ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            ã‚ãªãŸã®ã€å”¯ä¸€ã®ã€ä»»å‹™ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã€æ¸¡ã•ã‚ŒãŸã€æ—¥æœ¬èªã‚’ã€åˆ†æã—ã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®ç•°ãªã‚‹ã€3ã¤ã®ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã€è‹±è¨³å€™è£œã‚’ã€ç”Ÿæˆã—ã€ä»¥ä¸‹ã®ã€JSONå½¢å¼ã§ã€å³æ ¼ã«ã€å‡ºåŠ›ã™ã‚‹ã“ã¨ã§ã™ã€‚
            ## JSONå‡ºåŠ›ã«é–¢ã™ã‚‹ã€çµ¶å¯¾çš„ãªã€å¥‘ç´„æ¡ä»¶ï¼š
            ã‚ãªãŸã®å›ç­”ã¯ã€å¿…ãšã€ä»¥ä¸‹ã®JSONæ§‹é€ ã«ã€å³å¯†ã«ã€å¾“ã†ã“ã¨ã€‚ã“ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä»¥å¤–ã®ã€ã„ã‹ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚‚ã€çµ¶å¯¾ã«ã€çµ¶å¯¾ã«ã€å«ã‚ã¦ã¯ãªã‚‰ãªã„ã€‚
            ```json
            {
              "candidates": [
                {
                  "translation": "ã“ã“ã«ã€1ã¤ç›®ã®ã€æœ€ã‚‚ã€æ¨™æº–çš„ãªã€ç¿»è¨³å€™è£œã‚’è¨˜è¿°ã—ã¾ã™ã€‚",
                  "nuance": "ã“ã®ç¿»è¨³ãŒæŒã¤ã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ï¼ˆä¾‹ï¼šã€Œæœ€ã‚‚ä¸€èˆ¬çš„ã€ã€Œãƒ•ã‚©ãƒ¼ãƒãƒ«ã€ãªã©ï¼‰ã‚’ã€ç°¡æ½”ã«ã€èª¬æ˜ã—ã¾ã™ã€‚"
                },
                {
                  "translation": "ã“ã“ã«ã€2ã¤ç›®ã®ã€å°‘ã—ã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®ç•°ãªã‚‹ã€ç¿»è¨³å€™è£œã‚’è¨˜è¿°ã—ã¾ã™ã€‚",
                  "nuance": "ã“ã®ç¿»è¨³ãŒæŒã¤ã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ï¼ˆä¾‹ï¼šã€Œã‚ˆã‚Šä¸å¯§ã€ã€Œã‚„ã‚„å©‰æ›²çš„ã€ãªã©ï¼‰ã‚’ã€ç°¡æ½”ã«ã€èª¬æ˜ã—ã¾ã™ã€‚"
                },
                {
                  "translation": "ã“ã“ã«ã€3ã¤ç›®ã®ã€ã•ã‚‰ã«ã€ç•°ãªã‚‹ã€è¦–ç‚¹ã‹ã‚‰ã®ã€ç¿»è¨³å€™è£œã‚’è¨˜è¿°ã—ã¾ã™ã€‚",
                  "nuance": "ã“ã®ç¿»è¨³ãŒæŒã¤ã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ï¼ˆä¾‹ï¼šã€Œæœ€ã‚‚ç°¡æ½”ã€ã€Œç›´æ¥çš„ã€ãªã©ï¼‰ã‚’ã€ç°¡æ½”ã«ã€èª¬æ˜ã—ã¾ã™ã€‚"
                }
              ]
            }
            ```
            ## æœ€é‡è¦ãƒ«ãƒ¼ãƒ«:
            - `translation` ã¯ã€å¿…ãšã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªè‹±èªã§ã€è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚
            - `nuance` ã¯ã€å¿…ãšã€ãã®ã€é•ã„ãŒã€ä¸€ç›®ã§ã‚ã‹ã‚‹ã€**ç°¡æ½”ãªã€æ—¥æœ¬èªã€‘**ã§ã€è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚
            """
            request_contents = [system_prompt, processed_text]
            response = model.generate_content(request_contents)
            raw_response_text = response.text
        
        # --- ã€JSONç´”åŒ–è£…ç½®ã€ãŒã€å¤‰ã‚ã‚‰ãšã€æˆ‘ã€…ã‚’ã€å®ˆã‚‹ (å¤‰æ›´ãªã—) ---
        json_start_index = raw_response_text.find('{')
        json_end_index = raw_response_text.rfind('}')
        if json_start_index != -1 and json_end_index != -1:
            pure_json_text = raw_response_text[json_start_index : json_end_index + 1]
            try:
                translated_proposals = json.loads(pure_json_text)
                return original_input_display, translated_proposals
            except json.JSONDecodeError:
                st.error("AIãŒç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ãŒç ´æã—ã¦ã„ã¾ã—ãŸã€‚ãŠæ‰‹æ•°ã§ã™ãŒã€ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                print("ã€JSONæ§‹é€ ç ´æã‚¨ãƒ©ãƒ¼ã€‘ç´”åŒ–å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ:", pure_json_text)
                return None, None
        else:
            st.error("AIã‹ã‚‰äºˆæœŸã›ã¬å½¢å¼ã®å¿œç­”ãŒã‚ã‚Šã¾ã—ãŸã€‚JSONãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            print("ã€éJSONå¿œç­”ã‚¨ãƒ©ãƒ¼ã€‘AIã®ç”Ÿå¿œç­”:", raw_response_text)
            return None, None

    # --- ã€äºŒæ®µæ§‹ãˆã®è¿æ’ƒã‚·ã‚¹ãƒ†ãƒ ã€ã‚‚ã€å¥åœ¨ (å¤‰æ›´ãªã—) ---
    except exceptions.ResourceExhausted as e:
        st.error("APIã‚­ãƒ¼ã®ä¸Šé™ã«é”ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å°‘ã—æ™‚é–“ã‚’ã‚ã‘ã‚‹ã‹ã€æ˜æ—¥ä»¥é™ã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        return None, None
    except Exception as e:
        error_message = str(e).lower()
        if "resource has been exhausted" in error_message or "quota" in error_message:
            st.error("APIã‚­ãƒ¼ã®ä¸Šé™ã«é”ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å°‘ã—æ™‚é–“ã‚’ã‚ã‘ã‚‹ã‹ã€æ˜æ—¥ä»¥é™ã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            st.error(f"AIå‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None

# ===============================================================
# ãƒ¡ã‚¤ãƒ³ã®ä»•äº‹ (è¡¨ç¤ºéƒ¨åˆ†ã‚’ã€ã‚·ãƒ³ãƒ—ãƒ«ã«ã€ç¾ã—ãã€å†è¨­è¨ˆ)
# ===============================================================
def show_tool(gemini_api_key):
    if st.query_params.get("unlocked") == "true":
        st.session_state.translator_usage_count = 0
        st.query_params.clear()
        st.toast("ãŠã‹ãˆã‚Šãªã•ã„ï¼åˆ©ç”¨å›æ•°ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚")
        st.balloons()
        time.sleep(1)
        st.rerun()

    st.header("ğŸ¤ ç¿»è¨³ãƒ„ãƒ¼ãƒ«", divider='rainbow')

    if "translator_results" not in st.session_state: st.session_state.translator_results = []
    if "translator_last_mic_id" not in st.session_state: st.session_state.translator_last_mic_id = None
    if "text_to_process" not in st.session_state: st.session_state.text_to_process = None
    if "translator_last_input" not in st.session_state: st.session_state.translator_last_input = ""
    if "translator_usage_count" not in st.session_state: st.session_state.translator_usage_count = 0

    usage_limit = 5
    is_limit_reached = st.session_state.translator_usage_count >= usage_limit

    audio_info = None

    if is_limit_reached:
        st.success("ğŸ‰ ãŸãã•ã‚“ã®ã”åˆ©ç”¨ã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼")
        st.info("ã“ã®ãƒ„ãƒ¼ãƒ«ãŒã€ã‚ãªãŸã®ä¸–ç•Œã‚’åºƒã’ã‚‹ä¸€åŠ©ã¨ãªã‚Œã°å¹¸ã„ã§ã™ã€‚\n\nä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰å¿œæ´ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã™ã‚‹ã“ã¨ã§ã€ç¿»è¨³ã‚’ç¶šã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")
        portal_url = "https://pray-power-is-god-and-cocoro.com/free3/continue.html"
        st.link_button("å¿œæ´ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¦ã€ç¿»è¨³ã‚’ç¶šã‘ã‚‹", portal_url, type="primary")
    else:
        st.info("ãƒã‚¤ã‚¯ã§æ—¥æœ¬èªã‚’è©±ã™ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®ç•°ãªã‚‹3ã¤ã®ç¿»è¨³å€™è£œã‚’ææ¡ˆã—ã¾ã™ã€‚")
        st.caption(f"ğŸš€ ã‚ã¨ {usage_limit - st.session_state.translator_usage_count} å›ã€ææ¡ˆã‚’å—ã‘ã‚‰ã‚Œã¾ã™ã€‚å¿œæ´å¾Œã€æ®‹ã‚Šã®å›æ•°ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™ã€‚")
        with st.expander("ğŸ’¡ ã“ã®ãƒ„ãƒ¼ãƒ«ã®AIã«ã¤ã„ã¦"):
            st.markdown("""
            ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€Googleã®**Gemini 1.5 Flash**ã¨ã„ã†AIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
            ç¾åœ¨ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã«ã¯**1åˆ†ã‚ãŸã‚Š15å›ã€1æ—¥ã‚ãŸã‚Š1,500å›ã¾ã§**ã®ç„¡æ–™åˆ©ç”¨æ ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚
            å¿ƒã‚†ãã¾ã§ã€è¨€èªã®å£ã‚’è¶Šãˆã‚‹æ—…ã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ï¼
            """, unsafe_allow_html=True)
        def handle_text_input():
            st.session_state.text_to_process = st.session_state.translator_text
        col1, col2 = st.columns([1, 2])
        with col1:
            audio_info = mic_recorder(start_prompt="ğŸ¤ è©±ã—å§‹ã‚ã‚‹", stop_prompt="â¹ï¸ ææ¡ˆã‚’å—ã‘ã‚‹", key='translator_mic', format="webm")
        with col2:
            st.text_input("ã¾ãŸã¯ã€ã“ã“ã«æ—¥æœ¬èªã‚’å…¥åŠ›ã—ã¦Enter...", key="translator_text", on_change=handle_text_input)

    content_to_process = None
    if audio_info and audio_info['id'] != st.session_state.translator_last_mic_id:
        content_to_process = audio_info['bytes']
        st.session_state.translator_last_mic_id = audio_info['id']
    elif st.session_state.text_to_process:
        content_to_process = st.session_state.text_to_process
        st.session_state.text_to_process = None

    if content_to_process and content_to_process != st.session_state.translator_last_input:
        st.session_state.translator_last_input = content_to_process
        if not gemini_api_key:
            st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            original, proposals_data = translate_with_gemini(content_to_process, gemini_api_key)
            
            if proposals_data and "candidates" in proposals_data: # â˜…â˜…â˜… ã‚­ãƒ¼ã‚’'proposals'ã‹ã‚‰'candidates'ã«å¤‰æ›´ â˜…â˜…â˜…
                st.session_state.translator_usage_count += 1
                st.session_state.translator_results.insert(0, {"original": original, "candidates": proposals_data["candidates"]})
                st.rerun()
            else:
                st.session_state.translator_last_input = ""

    # â˜…â˜…â˜… ã“ã“ãŒã€ã‚·ãƒ³ãƒ—ãƒ«ã«ã€ç”Ÿã¾ã‚Œå¤‰ã‚ã£ãŸã€æˆ‘ã€…ã®ã€é™³åˆ—æ£šã§ã™ â˜…â˜…â˜…
    if st.session_state.translator_results:
        st.write("---")
        for i, result in enumerate(st.session_state.translator_results):
            with st.container(border=True):
                st.markdown(f"#### å±¥æ­´ No.{len(st.session_state.translator_results) - i}")
                st.markdown(f"**ğŸ‡¯ğŸ‡µ ã‚ãªãŸã®å…¥åŠ›:** {result['original']}")
                
                if "candidates" in result and isinstance(result["candidates"], list):
                    st.write("---")
                    # 3ã¤ã®å€™è£œã‚’ã€ç¾ã—ãã€æ¨ªã«ã€ä¸¦ã¹ã¾ã™
                    cols = st.columns(len(result["candidates"]))
                    for col_index, candidate in enumerate(result["candidates"]):
                        with cols[col_index]:
                            nuance = candidate.get('nuance', 'N/A')
                            translation = candidate.get('translation', 'ç¿»è¨³ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ')
                            st.info(f"**{nuance}**")
                            st.success(f"{translation}")

        if st.button("ç¿»è¨³å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", key="clear_translator_history"):
            st.session_state.translator_results = []
            st.session_state.translator_last_input = ""
            st.rerun()
