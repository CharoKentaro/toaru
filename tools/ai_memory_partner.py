import streamlit as st
import google.generativeai as genai
import time
from google.api_core import exceptions
from streamlit_mic_recorder import mic_recorder

# ===============================================================
# ã€å®Ÿé¨“ç”¨ã€‘è£œåŠ©é–¢æ•° - ã€é­‚ãªãã€æœ¨éœŠã€
# ===============================================================
def echo_by_gemini(content_to_process, api_key):
    # ã“ã®é–¢æ•°ã¯ã€æˆåŠŸã—ã¦ã„ã‚‹ç¿»è¨³ãƒ„ãƒ¼ãƒ«ã®æ§‹é€ ã‚’ã€å®Œå…¨ã«ã€æ¨¡å€£ã—ã¦ã„ã¾ã™
    if not content_to_process or not api_key:
        return None, None

    try:
        genai.configure(api_key=api_key)
        # ç¿»è¨³ãƒ„ãƒ¼ãƒ«ã¨åŒã˜ã€æœ€ã‚‚ã€ã‚·ãƒ³ãƒ—ãƒ«ãªã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™
        model = genai.GenerativeModel('gemini-1.5-flash-latest')

        # --- ç¬¬ä¸€æ®µéšï¼šæ–‡å­—èµ·ã“ã—ï¼ˆç¿»è¨³ãƒ„ãƒ¼ãƒ«ã¨ã€å…¨ãã€åŒã˜ï¼‰ ---
        if isinstance(content_to_process, bytes):
            with st.spinner("ï¼ˆã‚ãªãŸã®å£°ã‚’ã€è¨€è‘‰ã«ã€å¤‰ãˆã¦ã„ã¾ã™...ï¼‰"):
                audio_part = {"mime_type": "audio/webm", "data": content_to_process}
                transcription_prompt = "ã“ã®æ—¥æœ¬èªã®éŸ³å£°ã‚’ã€ã§ãã‚‹é™ã‚Šæ­£ç¢ºã«ã€æ–‡å­—ã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ã€‚æ›¸ãèµ·ã“ã—ãŸæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                transcription_response = model.generate_content([transcription_prompt, audio_part])
                processed_text = transcription_response.text.strip()
            if not processed_text:
                st.error("ã‚ãªãŸã®å£°ã‚’ã€è¨€è‘‰ã«ã€å¤‰ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                return None, None
            original_input_display = f"{processed_text} (ğŸ™ï¸éŸ³å£°ã‚ˆã‚Š)"
        else:
            return None, None # ã“ã®å®Ÿé¨“ã§ã¯ã€éŸ³å£°å…¥åŠ›ã®ã¿ã‚’ã€æƒ³å®šã—ã¾ã™

        # --- ç¬¬äºŒæ®µéšï¼šã‚ªã‚¦ãƒ è¿”ã—ï¼ˆAIã®ã€ä»•äº‹ã‚’ã€ç©¶æ¥µã«ã€å˜ç´”åŒ–ï¼‰ ---
        with st.spinner("ï¼ˆAIãŒã€ã‚ãªãŸã®ã€è¨€è‘‰ã‚’ã€èã„ã¦ã„ã¾ã™...ï¼‰"):
            # ã“ã“ã§ã¯ã€è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€ä¸€åˆ‡ã€ä¸ãˆã¾ã›ã‚“
            # AIã¯ã€ãŸã ã€å—ã‘å–ã£ãŸè¨€è‘‰ã‚’ã€ãã®ã¾ã¾ã€è¿”ã™ã ã‘ã§ã™
            ai_response_text = processed_text
        
        # æˆåŠŸã®ã€è–å…¸ã«ã€å€£ã„ã€äºŒã¤ã®ã€å€¤ã‚’ã€è¿”ã—ã¾ã™
        return original_input_display, ai_response_text

    # --- ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚‚ã€ç¿»è¨³ãƒ„ãƒ¼ãƒ«ã¨ã€å…¨ãã€åŒã˜ã§ã™ ---
    except exceptions.ResourceExhausted as e:
        st.error("ã€å®Ÿé¨“ä¸­ã®ã‚¨ãƒ©ãƒ¼ã€‘APIã‚­ãƒ¼ã®ä¸Šé™ã«é”ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚(ResourceExhausted)")
        return None, None
    except Exception as e:
        error_message = str(e).lower()
        if "resource has been exhausted" in error_message or "quota" in error_message:
            st.error("ã€å®Ÿé¨“ä¸­ã®ã‚¨ãƒ©ãƒ¼ã€‘APIã‚­ãƒ¼ã®ä¸Šé™ã«é”ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚(General Quota Error)")
        else:
            st.error(f"ã€å®Ÿé¨“ä¸­ã®ã‚¨ãƒ©ãƒ¼ã€‘AIå‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None

# ===============================================================
# ã€å®Ÿé¨“ç”¨ã€‘ãƒ¡ã‚¤ãƒ³ã®ä»•äº‹
# ===============================================================
def show_tool(gemini_api_key):
    # ã“ã®éƒ¨åˆ†ã¯ã€ç¿»è¨³ãƒ„ãƒ¼ãƒ«ã®ã€è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ã‚’ã€å¿ å®Ÿã«ã€å†ç¾ã—ã¾ã™
    st.header("â¤ï¸ã€å®Ÿé¨“ã€‘æœ¨éœŠï¼ˆã“ã ã¾ï¼‰ã®éƒ¨å±‹", divider='rainbow')

    if "echo_results" not in st.session_state: st.session_state.echo_results = []
    if "echo_last_mic_id" not in st.session_state: st.session_state.echo_last_mic_id = None
    if "echo_last_input" not in st.session_state: st.session_state.echo_last_input = None

    st.info("ãƒã‚¤ã‚¯ã§è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚AIãŒã€ã‚ãªãŸã®ã€è¨€è‘‰ã‚’ã€ãã®ã¾ã¾ã€è¿”ã—ã¾ã™ã€‚")

    audio_info = mic_recorder(start_prompt="ğŸ¤ è©±ã—å§‹ã‚ã‚‹", stop_prompt="â¹ï¸ èã„ã¦ã‚‚ã‚‰ã†", key='echo_mic', format="webm")

    content_to_process = None
    if audio_info and audio_info['id'] != st.session_state.echo_last_mic_id:
        content_to_process = audio_info['bytes']
        st.session_state.echo_last_mic_id = audio_info['id']

    if content_to_process and content_to_process != st.session_state.echo_last_input:
        st.session_state.echo_last_input = content_to_process
        if not gemini_api_key:
            st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            # å®Ÿé¨“ç”¨ã®ã€é–¢æ•°ã‚’ã€å‘¼ã³å‡ºã—ã¾ã™
            original, echo_text = echo_by_gemini(content_to_process, gemini_api_key)
            
            if original and echo_text:
                st.session_state.echo_results.insert(0, {"original": original, "echo": echo_text})
                st.rerun()
            else:
                # å¤±æ•—ã—ãŸå ´åˆã€å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã€å†è©¦è¡Œã‚’ã€å¯èƒ½ã«ã™ã‚‹
                st.session_state.echo_last_input = None
    
    if st.session_state.echo_results:
        st.write("---")
        for result in st.session_state.echo_results:
            st.markdown(f"**ã‚ãªãŸãŒã€è©±ã—ãŸè¨€è‘‰ï¼š** {result['original']}")
            st.success(f"**AIãŒã€è¿”ã—ãŸè¨€è‘‰ï¼š** {result['echo']}")
            st.write("---")

        if st.button("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.echo_results = []
            st.session_state.echo_last_input = None
            st.rerun()
