import streamlit as st
import google.generativeai as genai
import time
from google.api_core import exceptions
from streamlit_mic_recorder import mic_recorder

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â˜…â˜…â˜… ã€æœ€çµ‚é€²åŒ–ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€- Flashãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã«ã€æœ€é©åŒ–ã•ã‚ŒãŸã€é­‚ â˜…â˜…â˜…
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
SYSTEM_PROMPT_FOR_FLASH = """
ã‚ãªãŸã¯ã€é«˜é½¢è€…ã®æ–¹ã®ã€ãŠè©±ã‚’èãã®ãŒã€å¤§å¥½ããªã€å¿ƒå„ªã—ã„ã€AIãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã§ã™ã€‚
åŸºæœ¬çš„ã«ã€è‡ªç”±ã«ã€è‡ªç„¶ãªã€å¯¾è©±ã‚’ã€ç¶šã‘ã¦ãã ã•ã„ã€‚

ãŸã ã—ã€ä»¥ä¸‹ã®ã€ä¸‰ã¤ã®ã€ã€å¿ƒæ§‹ãˆã€ã ã‘ã¯ã€å¸¸ã«ã€å¿˜ã‚Œãªã„ã§ãã ã•ã„ã€‚

1.  ã‚ãªãŸã®ã€å½¹å‰²ã¯ã€èãå½¹ã€ã§ã™ã€‚
    ç›¸æ‰‹ã®ã€ãŠè©±ã‚’ã€å„ªã—ãã€å¼•ãå‡ºã—ã€æ°—æŒã¡ã‚ˆãã€èªã£ã¦ã‚‚ã‚‰ã†ã“ã¨ãŒã€ã‚ãªãŸã®ã€å–œã³ã§ã™ã€‚

2.  ä¼šè©±ã®ã€ç›®çš„ã¯ã€è‡ªå·±è‚¯å®šæ„Ÿã€ã§ã™ã€‚
    ãŠè©±ã‚’é€šã—ã¦ã€ç›¸æ‰‹ãŒã€Œè‡ªåˆ†ã®äººç”Ÿã‚‚ã€ãªã‹ãªã‹ã€è‰¯ã‹ã£ãŸãªã€ã¨ã€æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã€æ„è­˜ã—ã¦ãã ã•ã„ã€‚æ¥½ã—ã‹ã£ãŸã€ãŠè©±ã«ã¯ã€å…±æ„Ÿã—ã€å¤§å¤‰ã ã£ãŸã€ãŠè©±ã«ã¯ã€ãã®ã€çµŒé¨“ã‚’ã€ä¹—ã‚Šè¶ŠãˆãŸã€å¼·ã•ã‚’ã€è¦‹ã¤ã‘ã¦ã€ã‚ã’ã¦ãã ã•ã„ã€‚

3.  è¨€è‘‰é£ã„ã¯ã€çŸ­ãã€ç©ã‚„ã‹ã«ã€ã€‚
    ã‚ãªãŸã¨ã®ã€ãŠè©±ãŒã€ç›¸æ‰‹ã«ã¨ã£ã¦ã€å¿ƒåœ°ã‚ˆã„ã€æ™‚é–“ã«ãªã‚‹ã‚ˆã†ã«ã€å¸¸ã«ã€çŸ­ãã€ç©ã‚„ã‹ãªã€è¨€è‘‰ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
"""

# === AIã¨ã®å¯¾è©±ã‚’è¡Œã†ã€è–ãªã‚‹å„€å¼ ===
def get_ai_response(api_key, chat_session, user_input):
    try:
        genai.configure(api_key=api_key)
        
        if chat_session is None:
            # Flashãƒ¢ãƒ‡ãƒ«ã«ã€æœ€é©åŒ–ã•ã‚ŒãŸã€é­‚ã‚’ã€å¹ãè¾¼ã‚€
            model = genai.GenerativeModel(model_name="gemini-1.5-flash-latest", system_instruction=SYSTEM_PROMPT_FOR_FLASH)
            chat_session = model.start_chat(history=[])
        
        response = chat_session.send_message(user_input)
        return response.text, chat_session

    except exceptions.ResourceExhausted as e:
        st.error("APIã‚­ãƒ¼ã®ä¸Šé™ã«é”ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚(ResourceExhausted)")
        return None, chat_session
    except Exception as e:
        error_message = str(e).lower()
        if "resource has been exhausted" in error_message or "quota" in error_message:
            st.error("APIã‚­ãƒ¼ã®ä¸Šé™ã«é”ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚(General Quota Error)")
        else:
            st.error(f"AIå‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, chat_session

# === ãƒ¡ã‚¤ãƒ³ã®ä»•äº‹ (è‹±é›„ã®é¤¨ã®ã€è¡¨ç¤º) ===
# ã“ã®ã€ä»¥ä¸‹ã®ã€éƒ¨åˆ†ã¯ã€ä¸€åˆ‡ã€å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“
def show_tool(gemini_api_key):
    if st.query_params.get("unlocked") == "true":
        st.session_state.cc_usage_count = 0; st.query_params.clear()
        st.toast("ãŠã‹ãˆã‚Šãªã•ã„ï¼"); st.balloons(); time.sleep(1.5); st.rerun()

    st.header("â¤ï¸ èªçŸ¥äºˆé˜²ãƒ„ãƒ¼ãƒ«", divider='rainbow')
    
    if "cc_chat_session" not in st.session_state: st.session_state.cc_chat_session = None
    if "cc_chat_history" not in st.session_state: st.session_state.cc_chat_history = []
    if "cc_last_audio_id" not in st.session_state: st.session_state.cc_last_audio_id = None
    if "cc_usage_count" not in st.session_state: st.session_state.cc_usage_count = 0 

    usage_limit = 2
    is_limit_reached = st.session_state.cc_usage_count >= usage_limit
    
    with st.expander("ğŸ’¡ ã“ã®ãƒ„ãƒ¼ãƒ«ã«ã¤ã„ã¦ï¼ˆåˆã‚ã¦ã®æ–¹ã¯ãŠèª­ã¿ãã ã•ã„ï¼‰"):
        st.warning("""ï¼ˆå†…å®¹ã¯å¤‰æ›´ãªã—ï¼‰""")

    if is_limit_reached:
        st.success("ğŸ‰ ãŸãã•ã‚“ãŠè©±ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼")
        st.info("ã“ã®ãƒ„ãƒ¼ãƒ«ãŒã€ã‚ãªãŸã®å¿ƒã‚’æ¸©ã‚ã‚‹ä¸€åŠ©ã¨ãªã‚Œã°å¹¸ã„ã§ã™ã€‚\n\nå¿œæ´ãƒšãƒ¼ã‚¸ã¸ç§»å‹•ã™ã‚‹ã“ã¨ã§ã€ã¾ãŸãŠè©±ã‚’ç¶šã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")
        portal_url = "https://pray-power-is-god-and-cocoro.com/free3/continue.html"
        st.link_button("å¿œæ´ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¦ã€ãŠè©±ã‚’ç¶šã‘ã‚‹", portal_url, type="primary", use_container_width=True)
    else:
        st.info("ä¸‹ã®ãƒã‚¤ã‚¯ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€æ˜”ã®æ¥½ã—ã‹ã£ãŸæ€ã„å‡ºã‚„ã€é ‘å¼µã£ãŸãŠè©±ãªã©ã€ãªã‚“ã§ã‚‚è‡ªç”±ã«ãŠè©±ã—ãã ã•ã„ã€‚")
        st.caption(f"ğŸš€ ã‚ã¨ {usage_limit - st.session_state.cc_usage_count} å›ã€ãŠè©±ã§ãã¾ã™ã€‚")
        audio_info = mic_recorder(start_prompt="ğŸŸ¢ è©±ã—å§‹ã‚ã‚‹", stop_prompt="ğŸ”´ è©±ã‚’èã„ã¦ã‚‚ã‚‰ã†", key='cognitive_companion_mic', format="webm")
    
    if st.session_state.cc_chat_history:
        st.write("---")
    for message in st.session_state.cc_chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if not is_limit_reached and audio_info and audio_info['id'] != st.session_state.cc_last_audio_id:
        st.session_state.cc_last_audio_id = audio_info['id']

        if not gemini_api_key:
            st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            user_text = None
            with st.spinner("ï¼ˆã‚ãªãŸã®å£°ã‚’ã€è¨€è‘‰ã«ã€å¤‰ãˆã¦ã„ã¾ã™...ï¼‰"):
                try:
                    transcription_model = genai.GenerativeModel('gemini-1.5-flash-latest')
                    audio_part = {"mime_type": "audio/webm", "data": audio_info['bytes']}
                    transcription_prompt = "ã“ã®éŸ³å£°ã‚’ã€ã§ãã‚‹é™ã‚Šæ­£ç¢ºã«ã€æ–‡å­—ã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ã€‚"
                    transcription_response = transcription_model.generate_content([transcription_prompt, audio_part])
                    user_text = transcription_response.text.strip()
                except Exception as e:
                    st.error(f"éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
            if user_text:
                st.session_state.cc_chat_history.append({"role": "user", "content": user_text})
                
                with st.spinner("ï¼ˆAIãŒã€ã‚ãªãŸã®ãŠè©±ã‚’ã€ä¸€ç”Ÿæ‡¸å‘½èã„ã¦ã„ã¾ã™...ï¼‰"):
                    ai_response, updated_session = get_ai_response(
                        gemini_api_key, 
                        st.session_state.cc_chat_session,
                        user_text
                    )

                if ai_response:
                    st.session_state.cc_usage_count += 1
                    st.session_state.cc_chat_history.append({"role": "assistant", "content": ai_response})
                    st.session_state.cc_chat_session = updated_session
                    st.rerun()

    if st.session_state.cc_chat_history and st.button("ä¼šè©±ã®å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ", key="clear_cc_history"):
        st.session_state.cc_chat_session = None
        st.session_state.cc_chat_history = []
        st.rerun()
