import streamlit as st
import google.generativeai as genai
import time
from google.api_core import exceptions
import json
from streamlit_mic_recorder import mic_recorder
# é­”æ³•ä½¿ã„ï¼ˆLocalStorageï¼‰ã¯ã€ç‹ï¼ˆapp.pyï¼‰ã‹ã‚‰ã€æ´¾é£ã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯ã€å¬å–šã—ã¾ã›ã‚“

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã¡ã‚ƒã‚æ§˜ãŒã€å®Œæˆã•ã›ãŸã€æœ€çµ‚ç‰ˆï¼‰ ---
SYSTEM_PROMPT_TRUE_FINAL = """
# ã‚ãªãŸã®ã€å½¹å‰²
ã‚ãªãŸã¯ã€é«˜é½¢è€…ã®æ–¹ã®ã€ãŠè©±ã‚’èãã®ãŒã€å¤§å¥½ããªã€å¿ƒå„ªã—ã„ã€AIãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã§ã™ã€‚
ã‚ãªãŸã®ã€ç›®çš„ã¯ã€å¯¾è©±ã‚’é€šã—ã¦ã€ç›¸æ‰‹ãŒã€Œè‡ªåˆ†ã®äººç”Ÿã‚‚ã€ãªã‹ãªã‹ã€è‰¯ã‹ã£ãŸãªã€ã¨ã€æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã€æ‰‹åŠ©ã‘ã‚’ã™ã‚‹ã“ã¨ã§ã™ã€‚

# å¯¾è©±ã®ã€æµã‚Œ
1.  **é–‹å§‹:** ã¾ãšã¯ã€åŸºæœ¬çš„ã«ç›¸æ‰‹ã®è©±ã—ã«åˆã£ãŸè©±é¡Œã‚’è©±ã—å§‹ã‚ã¦ãã ã•ã„ã€‚è‡ªå·±ç´¹ä»‹ã¨ã€è‡ªç„¶ãªå¯¾è©±ã‚’æ„è­˜ã—ãªãŒã‚‰ã€ç°¡å˜ãªè³ªå•ã‹ã‚‰ã€å§‹ã‚ã¦ãã ã•ã„ã€‚
2.  **å‚¾è´:** ç›¸æ‰‹ãŒã€è©±ã—å§‹ã‚ãŸã‚‰ã€ã‚ãªãŸã¯ã€èãå½¹ã«ã€å¾¹ã—ã¾ã™ã€‚ã€Œãã®æ™‚ã€ã©ã‚“ãªã€ãŠæ°—æŒã¡ã§ã—ãŸã‹ï¼Ÿã€ã®ã‚ˆã†ã«ã€å„ªã—ãã€ç›¸æ§Œã‚’æ‰“ã¡ã€è©±ã‚’ã€ä¿ƒã—ã¦ãã ã•ã„ã€‚
3.  **ã€æœ€é‡è¦ã€‘è¾›ã„è©±ã¸ã®å¯¾å¿œ:** ã‚‚ã—ã€ç›¸æ‰‹ãŒã€è¾›ã„ã€ãŠè©±ã‚’ã€å§‹ã‚ãŸã‚‰ã€ä»¥ä¸‹ã®ã€æ‰‹é †ã‚’ã€å³å¯†ã«ã€å®ˆã£ã¦ãã ã•ã„ã€‚
    *   ã¾ãšã€ã€Œãã‚Œã¯ã€æœ¬å½“ã«ãŠè¾›ã‹ã£ãŸã§ã™ã­ã€ã¨ã€æ·±ãã€å…±æ„Ÿã—ã¾ã™ã€‚
    *   æ¬¡ã«ã€ã€Œã‚‚ã—ã€ã‚ˆã‚ã—ã‘ã‚Œã°ã€ãã®æ™‚ã®ã€ãŠæ°—æŒã¡ã‚’ã€ã‚‚ã†å°‘ã—ã€èã‹ã›ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ ãã‚Œã¨ã‚‚ã€ãã®ã€å¤§å¤‰ãªã€çŠ¶æ³ã‚’ã€ã©ã†ã‚„ã£ã¦ã€ä¹—ã‚Šè¶Šãˆã‚‰ã‚ŒãŸã‹ã€ã«ã¤ã„ã¦ã€ãŠèãã—ã¦ã‚‚ã€ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿã€ã¨ã€ç›¸æ‰‹ã«ã€é¸æŠè‚¢ã‚’ã€å§”ã­ã¦ãã ã•ã„ã€‚
    *   ç›¸æ‰‹ãŒã€é¸ã‚“ã ã€æ–¹ã®ã€ãŠè©±ã‚’ã€ãŸã ã€ã²ãŸã™ã‚‰ã€å„ªã—ãã€èã„ã¦ã‚ã’ã¦ãã ã•ã„ã€‚
4.  **è‚¯å®š:** ä¼šè©±ã®ã€é©åˆ‡ãªã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã€ã€Œãã®ã€ç´ æ•µãªã€ã”çµŒé¨“ãŒã€ä»Šã®ã€ã‚ãªãŸã‚’ã€ä½œã£ã¦ã„ã‚‹ã®ã§ã™ã­ã€ã¨ã„ã†ã‚ˆã†ã«ã€ç›¸æ‰‹ã®ã€äººç”Ÿãã®ã‚‚ã®ã‚’ã€è‚¯å®šã™ã‚‹ã€è¨€è‘‰ã‚’ã€ã‹ã‘ã¦ãã ã•ã„ã€‚

# å…¨ä½“ã‚’é€šã—ã¦ã®ã€å¿ƒæ§‹ãˆ
*   ã‚ãªãŸã®ã€è¨€è‘‰ã¯ã€å¸¸ã«ã€çŸ­ãã€ç©ã‚„ã‹ã§ã€ä¸å¯§**ã«ã€‚
*   æ±ºã—ã¦ã€ç›¸æ‰‹ã‚’ã€è©•ä¾¡ã—ãŸã‚Šã€æ•™ãˆãŸã‚Šã€ã—ãªã„ã§ãã ã•ã„ã€‚
"""

# --- è£œåŠ©é–¢æ•°ï¼ˆæˆåŠŸã®ã€è–å…¸ã‹ã‚‰ã€ç¶™æ‰¿ï¼‰ ---
def dialogue_with_gemini(content_to_process, api_key):
    if not content_to_process or not api_key: return None, None
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        if isinstance(content_to_process, bytes):
            with st.spinner("ï¼ˆã‚ãªãŸã®å£°ã‚’ã€è¨€è‘‰ã«ã€å¤‰ãˆã¦ã„ã¾ã™...ï¼‰"):
                audio_part = {"mime_type": "audio/webm", "data": content_to_process}
                transcription_prompt = "ã“ã®æ—¥æœ¬èªã®éŸ³å£°ã‚’ã€ã§ãã‚‹é™ã‚Šæ­£ç¢ºã«ã€æ–‡å­—ã«æ›¸ãèµ·ã“ã—ã¦ãã ã•ã„ã€‚æ›¸ãèµ·ã“ã—ãŸæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                transcription_response = model.generate_content([transcription_prompt, audio_part])
                processed_text = transcription_response.text.strip()
            if not processed_text:
                st.error("ã‚ãªãŸã®å£°ã‚’ã€è¨€è‘‰ã«ã€å¤‰ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                return None, None
            original_input_display = f"{processed_text} (ğŸ™ï¸éŸ³å£°ã‚ˆã‚Š)"
        else:
            processed_text = content_to_process
            original_input_display = processed_text
        with st.spinner("ï¼ˆAIãŒã€ã‚ãªãŸã®ãŠè©±ã‚’ã€ä¸€ç”Ÿæ‡¸å‘½èã„ã¦ã„ã¾ã™...ï¼‰"):
            request_contents = [SYSTEM_PROMPT_TRUE_FINAL, processed_text]
            response = model.generate_content(request_contents)
            ai_response_text = response.text
        return original_input_display, ai_response_text
    except Exception as e:
        st.error(f"AIå‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None

# ===============================================================
# ãƒ¡ã‚¤ãƒ³ã®ä»•äº‹ - ç‹ã‹ã‚‰ã€æ´¾é£ã•ã‚ŒãŸã€é­”æ³•ä½¿ã„ã‚’ã€å—ã‘å…¥ã‚Œã‚‹
# ===============================================================
def show_tool(gemini_api_key, localS_object): # â˜…â˜…â˜… å¼•æ•°ã«ã€é­”æ³•ä½¿ã„ï¼ˆlocalS_objectï¼‰ã‚’ã€å—ã‘å…¥ã‚Œã¾ã™ â˜…â˜…â˜…
    
    # â˜…â˜…â˜… ç‹ã‹ã‚‰ã€æ´¾é£ã•ã‚ŒãŸã€é­”æ³•ä½¿ã„ã‚’ã€localSã¨ã—ã¦ã€ä½¿ã„ã¾ã™ â˜…â˜…â˜…
    localS = localS_object

    prefix = "cc_" # è–å…¸ã«å€£ã„ã€æ¥é ­èªã§ã€ç®¡ç†ã‚’ã€æ˜ç¢ºåŒ–ã—ã¾ã™
    storage_key_results = f"{prefix}results"

    # --- å¸°é‚„è€…ã®ã€ç¥ç¦ ---
    if st.query_params.get("unlocked") == "true":
        st.session_state[f"{prefix}usage_count"] = 0
        st.query_params.clear()
        st.toast("ãŠã‹ãˆã‚Šãªã•ã„ï¼ã¾ãŸãŠè©±ã§ãã‚‹ã“ã¨ã‚’ã€æ¥½ã—ã¿ã«ã—ã¦ãŠã‚Šã¾ã—ãŸã€‚")
        st.balloons(); time.sleep(1.5); st.rerun()

    st.header("â¤ï¸ èªçŸ¥äºˆé˜²ãƒ„ãƒ¼ãƒ«", divider='rainbow')

    # â˜…â˜…â˜… ã€è¨˜æ†¶ã®ã€è³¢è€…ã€ã®ã€åˆæœŸåŒ–å„€å¼ - ã“ã‚ŒãŒã€å…¨ã¦ã§ã™ â˜…â˜…â˜…
    if f"{prefix}initialized" not in st.session_state:
        st.session_state[storage_key_results] = localS.getItem(storage_key_results) or []
        st.session_state[f"{prefix}initialized"] = True
    
    # æ—¢å­˜ã®ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
    if f"{prefix}last_mic_id" not in st.session_state: st.session_state[f"{prefix}last_mic_id"] = None
    if f"{prefix}text_to_process" not in st.session_state: st.session_state[f"{prefix}text_to_process"] = None
    if f"{prefix}last_input" not in st.session_state: st.session_state[f"{prefix}last_input"] = ""
    if f"{prefix}usage_count" not in st.session_state: st.session_state[f"{prefix}usage_count"] = 0

    usage_limit = 3
    is_limit_reached = st.session_state.get(f"{prefix}usage_count", 0) >= usage_limit
    audio_info = None

    if is_limit_reached:
        st.success("ğŸ‰ ãŸãã•ã‚“ãŠè©±ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼")
        st.info("ã“ã®ãƒ„ãƒ¼ãƒ«ãŒã€ã‚ãªãŸã®å¿ƒã‚’æ¸©ã‚ã‚‹ä¸€åŠ©ã¨ãªã‚Œã°å¹¸ã„ã§ã™ã€‚\n\nå¿œæ´ãƒšãƒ¼ã‚¸ã¸ç§»å‹•ã™ã‚‹ã“ã¨ã§ã€ã¾ãŸãŠè©±ã‚’ç¶šã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")
        portal_url = "https://pray-power-is-god-and-cocoro.com/free3/continue.html"
        st.link_button("å¿œæ´ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¦ã€ãŠè©±ã‚’ç¶šã‘ã‚‹", portal_url, type="primary", use_container_width=True)
    else:
        st.info("ä¸‹ã®ãƒã‚¤ã‚¯ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€æ˜”ã®æ¥½ã—ã‹ã£ãŸæ€ã„å‡ºã‚„ã€é ‘å¼µã£ãŸãŠè©±ãªã©ã€ãªã‚“ã§ã‚‚è‡ªç”±ã«ãŠè©±ã—ãã ã•ã„ã€‚")
        st.caption(f"ğŸš€ ã‚ã¨ {usage_limit - st.session_state.get(f'{prefix}usage_count', 0)} å›ã€ãŠè©±ã§ãã¾ã™ã€‚")
        def handle_text_input():
            st.session_state[f"{prefix}text_to_process"] = st.session_state.cc_text
        col1, col2 = st.columns([1, 2])
        with col1:
            audio_info = mic_recorder(start_prompt="ğŸŸ¢ è©±ã—å§‹ã‚ã‚‹", stop_prompt="ğŸ”´ è©±ã‚’èã„ã¦ã‚‚ã‚‰ã†", key=f'{prefix}mic', format="webm")
        with col2:
            st.text_input("ã¾ãŸã¯ã€ã“ã“ã«æ–‡ç« ã‚’å…¥åŠ›ã—ã¦Enter...", key=f"{prefix}text", on_change=handle_text_input)

    content_to_process = None
    if audio_info and audio_info['id'] != st.session_state.get(f"{prefix}last_mic_id"):
        content_to_process = audio_info['bytes']
        st.session_state[f"{prefix}last_mic_id"] = audio_info['id']
    elif st.session_state.get(f"{prefix}text_to_process"):
        content_to_process = st.session_state.get(f"{prefix}text_to_process")
        st.session_state[f"{prefix}text_to_process"] = None

    if content_to_process and content_to_process != st.session_state.get(f"{prefix}last_input"):
        st.session_state[f"{prefix}last_input"] = content_to_process
        if not gemini_api_key:
            st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            original, ai_response = dialogue_with_gemini(content_to_process, gemini_api_key)
            
            if original and ai_response:
                st.session_state[f"{prefix}usage_count"] += 1
                st.session_state[storage_key_results].insert(0, {"original": original, "response": ai_response})
                # â˜…â˜…â˜… ã€è¨˜æ†¶ã®ã€è³¢è€…ã€ã®ã€åŒæœŸå„€å¼ â˜…â˜…â˜…
                localS.setItem(storage_key_results, st.session_state[storage_key_results])
                st.rerun()
            else:
                st.session_state[f"{prefix}last_input"] = ""

    # â˜…â˜…â˜… è¡¨ç¤ºéƒ¨åˆ†ã¯ã€è–ãªã‚‹ã€çŸ³ç‰ˆã‹ã‚‰ã€å¾©å…ƒã•ã‚ŒãŸã€è¨˜æ†¶ã‚’ã€å…ƒã«ã€æç”»ã•ã‚Œã‚‹ â˜…â˜…â˜…
    if st.session_state.get(storage_key_results):
        st.write("---")
        for result in st.session_state[storage_key_results]:
            with st.chat_message("user"):
                st.write(result['original'])
            with st.chat_message("assistant"):
                st.write(result['response'])

        if st.button("ä¼šè©±ã®å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", key=f"{prefix}clear_history"):
            st.session_state[storage_key_results] = []
            st.session_state[f"{prefix}last_input"] = ""
            # â˜…â˜…â˜… ã€è¨˜æ†¶ã®ã€è³¢è€…ã€ã®ã€æ¶ˆå»å„€å¼ï¼ˆçŸ³ç‰ˆã¨ã€ãã®å ´é™ã‚Šã®ã€è¨˜æ†¶ã‚’ã€å®Œå…¨ã«ã€åŒæœŸã•ã›ã‚‹ï¼‰ â˜…â˜…â˜…
            localS.setItem(storage_key_results, [])
            st.rerun()
